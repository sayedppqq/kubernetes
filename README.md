# Kubernetes
## Master node of k8s ##
The master node in Kubernetes is responsible for managing and coordinating the cluster's resources, scheduling applications, and monitoring the overall health of the cluster. Here is an overview of the process of the master node in Kubernetes:

1. **API Server**: The API server provides the interface for managing the Kubernetes cluster. It exposes the Kubernetes API, which can be used by users and applications to interact with the cluster.
2. **etcd**: etcd is a distributed key-value store that is used to store the configuration data for the Kubernetes cluster.
3. **Controller Manager**: The controller manager is responsible for managing and controlling the state of the Kubernetes cluster. It watches the state of the cluster stored in etcd and takes action to ensure that the desired state of the cluster matches the actual state of the cluster.
4. **Scheduler**: The scheduler is responsible for scheduling the application workloads to the worker nodes based on the available resources and application requirements. When a new pod is created, the scheduler selects a suitable worker node based on resource requirements, node affinity, and other policies.
5. Node Controller: The node controller is responsible for monitoring the state of the worker nodes. It detects when a node becomes unavailable and takes action to ensure that the pods running on the node are rescheduled to other nodes.
6. Cloud Controller Manager: The cloud controller manager is a collection of controllers that interact with the cloud provider's APIs to manage the underlying infrastructure.

Overall, the master node in Kubernetes performs a wide range of tasks to ensure that the cluster is running smoothly, and the applications are deployed and managed efficiently.
## Worker nodes of K8s ##
A node in Kubernetes is a worker machine that runs containerized applications. Each node is managed by the control plane and can run multiple containers. The containers run on a container runtime, such as Docker, which is installed on each node. The process of a node in Kubernetes involves communication between the Kubelet, which runs on each node, and the control plane to receive PodSpecs and ensure the containers are running and healthy. The Kubernetes control plane continuously monitors the health of each node and can reschedule containers from a failed node to a healthy one.

**The process of a node in Kubernetes involves:**

1. The **Kubelet**, which runs on each node, communicates with the control plane to receive the PodSpecs and ensures the containers described in the PodSpecs are running and healthy.
2. Each node runs a **container runtime**, such as Docker, to manage the containers.
3. The **kube-proxy** runs on each node and is responsible for managing network communication between Pods and services within the cluster.

## Config file of kubernetes ##

A Kubernetes configuration file, also known as a manifest file, is a YAML or JSON file that defines the desired state of a Kubernetes object. The configuration file specifies the object's properties, such as the container image to use, the number of replicas to create, and the desired state of the object.

Here are the major parts of a Kubernetes configuration file:

1. **`apiVersion`**: Specifies the version of the Kubernetes API that the object uses. For example, **`apiVersion: v1`** is used for most core Kubernetes objects, while **`apiVersion: apps/v1`** is used for higher-level objects such as deployments and statefulsets.
2. **`kind`**: Specifies the type of Kubernetes object being defined. For example, **`kind: Pod`** defines a Pod object, while **`kind: Deployment`** defines a Deployment object.
3. **`metadata`**: Specifies metadata for the object, such as the object's name and labels. Labels are used to group related objects together and can be used to filter and select objects.
4. **`spec`**: Specifies the desired state of the object, such as the number of replicas, container image, and resource requirements. The **`spec`** section is specific to each object type and contains different properties depending on the object.
5. **`status`**: Specifies the current status of the object. The **`status`** section is typically generated by Kubernetes and is read-only, so it is not typically specified in the configuration file. Self healing process of k8s is work based on the status flag holed in etcd. **if prev_status != cur_status , it will update the component.**

Here's an example of a Kubernetes configuration file for a Deployment object with annotations and comments:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
name: my-deployment # name of the deployment object
labels:
app: my-app # label to identify the deployment
annotations:
owner: john # annotation to provide additional information
spec:
replicas: 3 # number of replicas to create
selector:
matchLabels:
app: my-app # label to match the pods created by the deployment
template:
metadata:
labels:
app: my-app # label for the pod template
spec:
containers:
- name: my-container # name of the container
image: my-image:latest # container image to use
ports:
- containerPort: 8080 # port to expose on the container
```

## Communication inside of a pod ##

Communication between containers in a pod in Kubernetes is done through the local network stack of the pod, as if they were running on the same host. This means that containers in the same pod can communicate with each other using **`localhost`** or the pod's IP address.

Kubernetes creates a virtual network interface for each pod, which is shared by all the containers in the pod. Each container gets its own network namespace and can see the same virtual network interface, so they can communicate with each other using standard networking protocols like TCP/IP.

Here's an example of how containers in the same pod can communicate with each other using **`localhost`**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: container-1
    image: my-image:latest
    ports:
    - containerPort: 8080
  - name: container-2
    image: my-image:latest
    ports:
    - containerPort: 8081
```
In this example, the pod has two containers, each running on a separate port. The containers can communicate with each other using **`localhost`** and the appropriate port number. For example, **`container-1`** can communicate with **`container-2`** using **`localhost:8081`**.

Note that communication between containers in different pods is done through the Kubernetes service discovery mechanism, which allows pods to discover and communicate with each other using service names and DNS.

## Communication between pods ##

In a Kubernetes cluster, pods can communicate with each other through the network. Kubernetes provides a virtual network called a "pod network," which allows pods to communicate with each other as if they were on the same host, even if they are running on different nodes in the cluster.

There are different ways that pods can communicate with each other in a Kubernetes cluster:

1. Pod-to-pod communication: Pods can communicate with other pods in the same namespace using their IP addresses. Kubernetes assigns each pod a unique IP address, which allows them to communicate with other pods directly over the network.
2. Service-to-pod communication: Kubernetes Services provide a stable IP address and DNS name for a set of pods, allowing them to communicate with each other using the Service's IP address or DNS name. When a pod sends a request to a Service, the request is load-balanced across all the pods that are part of the Service.
3. Pod-to-Service communication: Pods can communicate with a Service by using its DNS name or IP address. When a pod sends a request to a Service, Kubernetes uses the Service's IP address to load-balance the request across all the pods that are part of the Service.

In addition to these methods, Kubernetes also provides other networking features that enable secure and efficient communication between pods, such as network policies and ingress controllers.

## Features of k8s ##

- Namespace:

In Kubernetes, a namespace is a logical boundary that separates and isolates different objects and resources within a cluster.

Namespaces help to avoid naming conflicts and ensure that resources are properly isolated, making it easier to manage and secure the cluster. For example, a team might create a separate namespace for each project or environment, such as development, staging, or production.

To create a Kubernetes namespace using a YAML file, You can also specify the namespace for other resources using the **`metadata.namespace`** field in their YAML definition. For example:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  namespace: my-namespace
spec:
  containers:
    - name: nginx
      image: nginx:latest
```

- Labels:

In Kubernetes, labels are key-value pairs that you can attach to objects such as pods, services, and deployments. Labels provide a way to organize and select objects based on their characteristics, such as their role, version, or environment.

In Kubernetes, labels are key-value pairs that you can attach to objects such as pods, services, and deployments. Labels provide a way to organize and select objects based on their characteristics, such as their role, version, or environment.

Here's an example of a Pod with labels:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  labels:
    app: my-app
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:latest
```

In this example, the Pod has two labels, app: my-appand tier: frontend. These labels can be used to select and manipulate the Pod in various ways. For example, you could use the kubectl labelcommand to add a new label to the Pod:

``` kubectl label pod my-pod version=1.0 ```

Labels are also commonly used to select objects for deployment or service creation. For example, you could use labels to select all Pods with a certain label and deploy a new version of the application:

```kubectl apply -f my-app-v2.yaml -l app=my-app```

This would deploy the new version of the application defined in my-app-v2.yaml
 to all Pods with the app: my-applabel.

 - ReplicaSet

[Resource](https://www.youtube.com/watch?v=UIVtDHaCSZ8&ab_channel=cloud-monk-cloudinplainenglish)

In Kubernetes, a ReplicaSet is an object that is used to ensure that a specified number of replicas (identical copies) of a Pod are running at all times.

A ReplicaSet is responsible for managing and maintaining the desired number of replicas of a Pod. It monitors the state of each replica and if any of the replicas go down, it automatically replaces it with a new one to ensure that the desired number of replicas is always maintained.

ReplicaSets can be defined using a declarative YAML file or a JSON file, which specifies the desired state of the replicas. The YAML or JSON file includes details such as the number of replicas, the Pod template to use, and any other required settings.

here's an example of a ReplicaSet definition in Kubernetes YAML code:

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: my-image
        ports:
        - containerPort: 80
```

This YAML code creates a ReplicaSet named **`my-replicaset`** with a desired state of three replicas. The **`selector`** field specifies that the ReplicaSet should manage all Pods with the **`app=my-app`** label. The **`template`** field specifies the Pod template that should be used for each replica managed by the ReplicaSet. In this example, the template contains a single container named **`my-container`** that uses the **`my-image`** image and exposes port 80.

When this YAML code is applied to a Kubernetes cluster, the ReplicaSet will create and manage three replicas of the specified Pod template. If any of the replicas go down, the ReplicaSet will automatically replace them to maintain the desired state of three replicas.